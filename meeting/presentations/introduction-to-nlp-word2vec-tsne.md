## Introduction to NLP, Word2Vec and TNSE
#### Presentation for meeting dated 27 January 2019 by Vinay Khobragade

# What is NLP?
NLP stands for Natural Language Processing.
In Layman's terms, it is a branch of Machine Learning which deals with understanding the language used by humans.

# What are embeddings?
Computers don't understand Natural Language as it is. They work with numerical data. After all, one can perform computations only with numerical data.
Fot this reason, we want to convert natural language into vectors containing numerical data. These vectors are embedddings.

So converting the natural language into embeddings is very important. For this, there are few ways available.
- Bag of Words
- Word2Vec
- GloVe (Global Vectors)
- BERT
- And more..

We are interested in Word2Vec today.

# Reference Links
- [How to get started with word2vec and how to make it work](https://medium.freecodecamp.org/how-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3)
- [Word Embedding with Word2Vec and Fasttext](https://towardsdatascience.com/word-embedding-with-word2vec-and-fasttext-a209c1d3e12c)
- [Learn TensorFlow, the Word2Vec model, and the TSNE algorithm using rock bands](https://medium.freecodecamp.org/learn-tensorflow-the-word2vec-model-and-the-tsne-algorithm-using-rock-bands-97c99b5dcb3a)
